{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "f1_graph_embeddings.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "mount_file_id": "1suBYElPMYVKxJZXx6vvJmn6DtsyGIYPJ",
   "authorship_tag": "ABX9TyODZDmoypMG4c1388obX9ua"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Preparing an environment, importing required libs"
   ],
   "metadata": {
    "id": "6l60oolNCtbL",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "NpiqNs_6BHJD",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1655820584513,
     "user_tz": -180,
     "elapsed": 62521,
     "user": {
      "displayName": "Никита Рогаленко",
      "userId": "07335219348058713837"
     }
    },
    "outputId": "e77c8871-5dd7-4059-b211-55129b26c4bc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-gpu<2.0,>=1.15.2 in ./venv/lib/python3.7/site-packages (1.15.5)\r\n",
      "Requirement already satisfied: ampligraph in ./venv/lib/python3.7/site-packages (1.4.0)\r\n",
      "Requirement already satisfied: wrapt>=1.11.1 in ./venv/lib/python3.7/site-packages (from tensorflow-gpu<2.0,>=1.15.2) (1.14.1)\r\n",
      "Requirement already satisfied: absl-py>=0.7.0 in ./venv/lib/python3.7/site-packages (from tensorflow-gpu<2.0,>=1.15.2) (1.1.0)\r\n",
      "Collecting numpy<1.19.0,>=1.16.0\r\n",
      "  Using cached numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\r\n",
      "Requirement already satisfied: h5py<=2.10.0 in ./venv/lib/python3.7/site-packages (from tensorflow-gpu<2.0,>=1.15.2) (2.10.0)\r\n",
      "Requirement already satisfied: tensorflow-estimator==1.15.1 in ./venv/lib/python3.7/site-packages (from tensorflow-gpu<2.0,>=1.15.2) (1.15.1)\r\n",
      "Requirement already satisfied: six>=1.10.0 in ./venv/lib/python3.7/site-packages (from tensorflow-gpu<2.0,>=1.15.2) (1.16.0)\r\n",
      "Requirement already satisfied: astor>=0.6.0 in ./venv/lib/python3.7/site-packages (from tensorflow-gpu<2.0,>=1.15.2) (0.8.1)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in ./venv/lib/python3.7/site-packages (from tensorflow-gpu<2.0,>=1.15.2) (0.2.0)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./venv/lib/python3.7/site-packages (from tensorflow-gpu<2.0,>=1.15.2) (3.3.0)\r\n",
      "Requirement already satisfied: protobuf>=3.6.1 in ./venv/lib/python3.7/site-packages (from tensorflow-gpu<2.0,>=1.15.2) (4.21.1)\r\n",
      "Requirement already satisfied: gast==0.2.2 in ./venv/lib/python3.7/site-packages (from tensorflow-gpu<2.0,>=1.15.2) (0.2.2)\r\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in ./venv/lib/python3.7/site-packages (from tensorflow-gpu<2.0,>=1.15.2) (1.1.2)\r\n",
      "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in ./venv/lib/python3.7/site-packages (from tensorflow-gpu<2.0,>=1.15.2) (1.15.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./venv/lib/python3.7/site-packages (from tensorflow-gpu<2.0,>=1.15.2) (1.1.0)\r\n",
      "Requirement already satisfied: wheel>=0.26 in ./venv/lib/python3.7/site-packages (from tensorflow-gpu<2.0,>=1.15.2) (0.37.1)\r\n",
      "Requirement already satisfied: grpcio>=1.8.6 in ./venv/lib/python3.7/site-packages (from tensorflow-gpu<2.0,>=1.15.2) (1.46.3)\r\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in ./venv/lib/python3.7/site-packages (from tensorflow-gpu<2.0,>=1.15.2) (1.0.8)\r\n",
      "Requirement already satisfied: sphinx-rtd-theme==0.4.3 in ./venv/lib/python3.7/site-packages (from ampligraph) (0.4.3)\r\n",
      "Requirement already satisfied: flake8>=3.7.7 in ./venv/lib/python3.7/site-packages (from ampligraph) (4.0.1)\r\n",
      "Requirement already satisfied: pytest>=3.5.1 in ./venv/lib/python3.7/site-packages (from ampligraph) (7.1.2)\r\n",
      "Requirement already satisfied: sphinxcontrib-bibtex==0.4.2 in ./venv/lib/python3.7/site-packages (from ampligraph) (0.4.2)\r\n",
      "Requirement already satisfied: setuptools>=36 in ./venv/lib/python3.7/site-packages (from ampligraph) (60.2.0)\r\n",
      "Requirement already satisfied: scipy>=1.3.0 in ./venv/lib/python3.7/site-packages (from ampligraph) (1.7.3)\r\n",
      "Requirement already satisfied: tqdm>=4.23.4 in ./venv/lib/python3.7/site-packages (from ampligraph) (4.64.0)\r\n",
      "Requirement already satisfied: pandas>=0.23.1 in ./venv/lib/python3.7/site-packages (from ampligraph) (1.3.5)\r\n",
      "Requirement already satisfied: pyyaml>=3.13 in ./venv/lib/python3.7/site-packages (from ampligraph) (6.0)\r\n",
      "Requirement already satisfied: rdflib>=4.2.2 in ./venv/lib/python3.7/site-packages (from ampligraph) (6.1.1)\r\n",
      "Requirement already satisfied: networkx>=2.3 in ./venv/lib/python3.7/site-packages (from ampligraph) (2.6.3)\r\n",
      "Requirement already satisfied: beautifultable>=0.7.0 in ./venv/lib/python3.7/site-packages (from ampligraph) (1.1.0)\r\n",
      "Requirement already satisfied: sphinx<3,>=2.2 in ./venv/lib/python3.7/site-packages (from ampligraph) (2.4.5)\r\n",
      "Requirement already satisfied: recommonmark==0.4.0 in ./venv/lib/python3.7/site-packages (from ampligraph) (0.4.0)\r\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in ./venv/lib/python3.7/site-packages (from ampligraph) (1.0.2)\r\n",
      "Requirement already satisfied: docutils>=0.11 in ./venv/lib/python3.7/site-packages (from recommonmark==0.4.0->ampligraph) (0.17.1)\r\n",
      "Requirement already satisfied: commonmark<=0.5.4 in ./venv/lib/python3.7/site-packages (from recommonmark==0.4.0->ampligraph) (0.5.4)\r\n",
      "Requirement already satisfied: pybtex>=0.20 in ./venv/lib/python3.7/site-packages (from sphinxcontrib-bibtex==0.4.2->ampligraph) (0.24.0)\r\n",
      "Requirement already satisfied: oset>=0.1.3 in ./venv/lib/python3.7/site-packages (from sphinxcontrib-bibtex==0.4.2->ampligraph) (0.1.3)\r\n",
      "Requirement already satisfied: pybtex-docutils>=0.2.0 in ./venv/lib/python3.7/site-packages (from sphinxcontrib-bibtex==0.4.2->ampligraph) (1.0.2)\r\n",
      "Requirement already satisfied: wcwidth in ./venv/lib/python3.7/site-packages (from beautifultable>=0.7.0->ampligraph) (0.2.5)\r\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in ./venv/lib/python3.7/site-packages (from flake8>=3.7.7->ampligraph) (0.6.1)\r\n",
      "Requirement already satisfied: importlib-metadata<4.3 in ./venv/lib/python3.7/site-packages (from flake8>=3.7.7->ampligraph) (4.2.0)\r\n",
      "Requirement already satisfied: pycodestyle<2.9.0,>=2.8.0 in ./venv/lib/python3.7/site-packages (from flake8>=3.7.7->ampligraph) (2.8.0)\r\n",
      "Requirement already satisfied: pyflakes<2.5.0,>=2.4.0 in ./venv/lib/python3.7/site-packages (from flake8>=3.7.7->ampligraph) (2.4.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in ./venv/lib/python3.7/site-packages (from pandas>=0.23.1->ampligraph) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in ./venv/lib/python3.7/site-packages (from pandas>=0.23.1->ampligraph) (2022.1)\r\n",
      "Requirement already satisfied: py>=1.8.2 in ./venv/lib/python3.7/site-packages (from pytest>=3.5.1->ampligraph) (1.11.0)\r\n",
      "Requirement already satisfied: iniconfig in ./venv/lib/python3.7/site-packages (from pytest>=3.5.1->ampligraph) (1.1.1)\r\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in ./venv/lib/python3.7/site-packages (from pytest>=3.5.1->ampligraph) (1.0.0)\r\n",
      "Requirement already satisfied: attrs>=19.2.0 in ./venv/lib/python3.7/site-packages (from pytest>=3.5.1->ampligraph) (21.4.0)\r\n",
      "Requirement already satisfied: tomli>=1.0.0 in ./venv/lib/python3.7/site-packages (from pytest>=3.5.1->ampligraph) (2.0.1)\r\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.7/site-packages (from pytest>=3.5.1->ampligraph) (21.3)\r\n",
      "Requirement already satisfied: pyparsing in ./venv/lib/python3.7/site-packages (from rdflib>=4.2.2->ampligraph) (3.0.9)\r\n",
      "Requirement already satisfied: isodate in ./venv/lib/python3.7/site-packages (from rdflib>=4.2.2->ampligraph) (0.6.1)\r\n",
      "Requirement already satisfied: joblib>=0.11 in ./venv/lib/python3.7/site-packages (from scikit-learn>=0.19.1->ampligraph) (1.1.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./venv/lib/python3.7/site-packages (from scikit-learn>=0.19.1->ampligraph) (3.1.0)\r\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in ./venv/lib/python3.7/site-packages (from sphinx<3,>=2.2->ampligraph) (1.0.1)\r\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in ./venv/lib/python3.7/site-packages (from sphinx<3,>=2.2->ampligraph) (1.0.3)\r\n",
      "Requirement already satisfied: requests>=2.5.0 in ./venv/lib/python3.7/site-packages (from sphinx<3,>=2.2->ampligraph) (2.28.0)\r\n",
      "Requirement already satisfied: Pygments>=2.0 in ./venv/lib/python3.7/site-packages (from sphinx<3,>=2.2->ampligraph) (2.12.0)\r\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in ./venv/lib/python3.7/site-packages (from sphinx<3,>=2.2->ampligraph) (2.2.0)\r\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in ./venv/lib/python3.7/site-packages (from sphinx<3,>=2.2->ampligraph) (0.7.12)\r\n",
      "Requirement already satisfied: imagesize in ./venv/lib/python3.7/site-packages (from sphinx<3,>=2.2->ampligraph) (1.3.0)\r\n",
      "Requirement already satisfied: babel!=2.0,>=1.3 in ./venv/lib/python3.7/site-packages (from sphinx<3,>=2.2->ampligraph) (2.10.3)\r\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp in ./venv/lib/python3.7/site-packages (from sphinx<3,>=2.2->ampligraph) (2.0.0)\r\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in ./venv/lib/python3.7/site-packages (from sphinx<3,>=2.2->ampligraph) (1.0.2)\r\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml in ./venv/lib/python3.7/site-packages (from sphinx<3,>=2.2->ampligraph) (1.1.5)\r\n",
      "Requirement already satisfied: Jinja2>=2.3 in ./venv/lib/python3.7/site-packages (from sphinx<3,>=2.2->ampligraph) (3.1.2)\r\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in ./venv/lib/python3.7/site-packages (from sphinx<3,>=2.2->ampligraph) (1.0.2)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./venv/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu<2.0,>=1.15.2) (3.3.4)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in ./venv/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu<2.0,>=1.15.2) (2.1.2)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in ./venv/lib/python3.7/site-packages (from importlib-metadata<4.3->flake8>=3.7.7->ampligraph) (4.2.0)\r\n",
      "Requirement already satisfied: zipp>=0.5 in ./venv/lib/python3.7/site-packages (from importlib-metadata<4.3->flake8>=3.7.7->ampligraph) (3.8.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.7/site-packages (from Jinja2>=2.3->sphinx<3,>=2.2->ampligraph) (2.1.1)\r\n",
      "Requirement already satisfied: latexcodec>=1.0.4 in ./venv/lib/python3.7/site-packages (from pybtex>=0.20->sphinxcontrib-bibtex==0.4.2->ampligraph) (2.0.1)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in ./venv/lib/python3.7/site-packages (from requests>=2.5.0->sphinx<3,>=2.2->ampligraph) (2.0.12)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./venv/lib/python3.7/site-packages (from requests>=2.5.0->sphinx<3,>=2.2->ampligraph) (1.26.9)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.7/site-packages (from requests>=2.5.0->sphinx<3,>=2.2->ampligraph) (3.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.7/site-packages (from requests>=2.5.0->sphinx<3,>=2.2->ampligraph) (2022.6.15)\r\n",
      "\u001B[33mWARNING: Error parsing requirements for numpy: [Errno 2] No such file or directory: '/home/dell/f1-knowledge-base/F1-knowledge-base/graph-embeddings/venv/lib/python3.7/site-packages/numpy-1.21.6.dist-info/METADATA'\u001B[0m\r\n",
      "Installing collected packages: numpy\r\n",
      "  Attempting uninstall: numpy\r\n",
      "    Found existing installation: numpy 1.21.6\r\n",
      "\u001B[31mERROR: Cannot uninstall numpy 1.21.6, RECORD file not found. You might be able to recover from this via: 'pip install --force-reinstall --no-deps numpy==1.21.6'.\u001B[0m\r\n",
      "\u001B[33mWARNING: You are using pip version 21.3.1; however, version 22.1.2 is available.\r\n",
      "You should consider upgrading via the '/home/dell/f1-knowledge-base/F1-knowledge-base/graph-embeddings/venv/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install \"tensorflow-gpu>=1.15.2,<2.0\" ampligraph"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ampligraph\n",
    "\n",
    "print(tf.version.VERSION)\n",
    "ampligraph.__version__"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "POQPYcW9C4ae",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1655820593945,
     "user_tz": -180,
     "elapsed": 2912,
     "user": {
      "displayName": "Никита Рогаленко",
      "userId": "07335219348058713837"
     }
    },
    "outputId": "8ef146e6-a367-4ccb-8c64-7dd8fac90c09",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dell/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.5\n"
     ]
    },
    {
     "data": {
      "text/plain": "'1.4.0'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "At first, we have to create pandas dataframe from triples extracted from ontology populated with individuals\n"
   ],
   "metadata": {
    "id": "KmY9rCUKEBYt",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from rdflib import Graph, URIRef\n",
    "\n",
    "\n",
    "ONTOLOGY_IRI = \"https://github.com/RogoGit/F1-knowledge-base/f1-ontology\"\n",
    "ONTOLOGY_PREFIX = \"f1\"\n",
    "POPULATED_ONTOLOGY_PATH  = '../ontology-with-individuals.owl'\n",
    "\n",
    "\n",
    "f1_graph = Graph().parse(POPULATED_ONTOLOGY_PATH, format=\"turtle\")\n",
    "triples_list = []\n",
    "\n",
    "for subject, predicate, triple_object in f1_graph.triples((None, None, None)):\n",
    "    if predicate.startswith(URIRef(ONTOLOGY_IRI)):\n",
    "        triples_list.append([ent.replace(ONTOLOGY_IRI + \"#\", ONTOLOGY_PREFIX + \":\") for ent in [subject, predicate, triple_object]])\n",
    "\n",
    "f1_df = pd.DataFrame(triples_list, columns = ['Subject', 'Predicate', 'Object'])\n",
    "print(f1_df)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3TBWScGIEOT3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1655820632111,
     "user_tz": -180,
     "elapsed": 32147,
     "user": {
      "displayName": "Никита Рогаленко",
      "userId": "07335219348058713837"
     }
    },
    "outputId": "dde48c24-040b-4d0a-8f83-9e2c8bffc154",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Subject  \\\n",
      "0       f1:qualifying_result_2005_turkish_grand_prix_d...   \n",
      "1       f1:race_result_2005_turkish_grand_prix_fisichella   \n",
      "2        f1:race_result_1982_brazilian_grand_prix_paletti   \n",
      "3                                    f1:driver_jacky_ickx   \n",
      "4         f1:race_result_1976_swedish_grand_prix_nelleman   \n",
      "...                                                   ...   \n",
      "362467    f1:race_result_2008_australian_grand_prix_sutil   \n",
      "362468  f1:race_result_1993_hungarian_grand_prix_blundell   \n",
      "362469                  f1:death_accident_harry_blanchard   \n",
      "362470        f1:race_result_1998_german_grand_prix_alesi   \n",
      "362471      f1:race_result_1990_british_grand_prix_suzuki   \n",
      "\n",
      "                            Predicate  \\\n",
      "0                     f1:driverNumber   \n",
      "1                             f1:grid   \n",
      "2       f1:grandPrixResultIsRelatedTo   \n",
      "3         f1:hasDriverGrandPrixResult   \n",
      "4                             f1:grid   \n",
      "...                               ...   \n",
      "362467                        f1:grid   \n",
      "362468                f1:driverNumber   \n",
      "362469                     f1:inEvent   \n",
      "362470                 f1:finalStatus   \n",
      "362471              f1:driverPosition   \n",
      "\n",
      "                                             Object  \n",
      "0                                                20  \n",
      "1                                                 2  \n",
      "2                        f1:driver_riccardo_paletti  \n",
      "3       f1:race_result_1974_spanish_grand_prix_ickx  \n",
      "4                                                 0  \n",
      "...                                             ...  \n",
      "362467                                           22  \n",
      "362468                                           26  \n",
      "362469     f1:grand_prix_1960_buenos_aires_1.000_km  \n",
      "362470                                     Finished  \n",
      "362471                                            6  \n",
      "\n",
      "[362472 rows x 3 columns]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next step is to create train and test samples for graph embedding training"
   ],
   "metadata": {
    "id": "rPstkqZRWtDk",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size:  (326225, 3)\n",
      "Test set size:  (36247, 3)\n"
     ]
    }
   ],
   "source": [
    "from ampligraph.evaluation import train_test_split_no_unseen \n",
    "\n",
    "X_train, X_test = train_test_split_no_unseen(np.array(triples_list), test_size=0.10, seed=0)\n",
    "\n",
    "print('Train set size: ', X_train.shape)\n",
    "print('Test set size: ', X_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now it is time to define ComplEx model and train model with train sample"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average ComplEx Loss:   0.110975: 100%|██████████| 300/300 [3:23:58<00:00, 40.79s/epoch]  \n"
     ]
    }
   ],
   "source": [
    "import tensorflow.contrib\n",
    "from ampligraph.latent_features import ComplEx, save_model\n",
    "\n",
    "model = ComplEx(batches_count=100,\n",
    "                epochs=300,\n",
    "                k=100,\n",
    "                eta=20,\n",
    "                optimizer='adam',\n",
    "                optimizer_params={'lr':1e-4},\n",
    "                loss='multiclass_nll',\n",
    "                regularizer='LP',\n",
    "                regularizer_params={'p':3, 'lambda':1e-5},\n",
    "                seed=0,\n",
    "                verbose=True)\n",
    "\n",
    "model.fit(X_train)\n",
    "save_model(model, './embedding_model.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to use already trained model we can run:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from ampligraph.latent_features import restore_model\n",
    "\n",
    "model = restore_model('./embedding_model.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next step is to ensure the model can be trained and evaluated correctly. The first of these is defining the filter that will be used to ensure that no negative statements generated by the corruption procedure are actually positives."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING - DeprecationWarning: use_default_protocol will be removed in future. Please use corrupt_side argument instead.\n",
      "WARNING - You are attempting to use 76775 distinct entities to generate synthetic negatives in the evaluation\n",
      "    protocol. This may be unnecessary and will lead to a 'harder' task. Besides, it will lead to a much slower\n",
      "    evaluation procedure. We recommended to set the 'corruption_entities' argument to a reasonably sized set\n",
      "    of entities. The size of corruption_entities depends on your domain-specific task.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dell/anaconda3/lib/python3.6/site-packages/ampligraph/evaluation/protocol.py:952: UserWarning: You are attempting to use 76775 distinct entities to generate synthetic negatives in the evaluation\n",
      "    protocol. This may be unnecessary and will lead to a 'harder' task. Besides, it will lead to a much slower\n",
      "    evaluation procedure. We recommended to set the 'corruption_entities' argument to a reasonably sized set\n",
      "    of entities. The size of corruption_entities depends on your domain-specific task.\n",
      "  warnings.warn(warn_msg % ent_for_corruption_size)\n",
      " 20%|█▉        | 7069/36247 [26:13<1:48:13,  4.49it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m~/anaconda3/lib/python3.6/contextlib.py\u001B[0m in \u001B[0;36m__exit__\u001B[0;34m(self, type, value, traceback)\u001B[0m\n\u001B[1;32m     98\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 99\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgen\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mthrow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtraceback\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    100\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mStopIteration\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mexc\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001B[0m in \u001B[0;36mget_controller\u001B[0;34m(self, default)\u001B[0m\n\u001B[1;32m   5479\u001B[0m                  self).get_controller(default) as g, context.graph_mode():\n\u001B[0;32m-> 5480\u001B[0;31m         \u001B[0;32myield\u001B[0m \u001B[0mg\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   5481\u001B[0m     \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.6/site-packages/ampligraph/latent_features/models/EmbeddingModel.py\u001B[0m in \u001B[0;36mget_ranks\u001B[0;34m(self, dataset_handle)\u001B[0m\n\u001B[1;32m   1684\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0m_\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meval_dataset_handle\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_size\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'test'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdisable\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mverbose\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1685\u001B[0;31m                 \u001B[0mrank\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msess\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrank\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1686\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meval_config\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'corrupt_side'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mconstants\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDEFAULT_CORRUPT_SIDE_EVAL\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m's,o'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001B[0m in \u001B[0;36mrun\u001B[0;34m(self, fetches, feed_dict, options, run_metadata)\u001B[0m\n\u001B[1;32m    955\u001B[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001B[0;32m--> 956\u001B[0;31m                          run_metadata_ptr)\n\u001B[0m\u001B[1;32m    957\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0mrun_metadata\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001B[0m in \u001B[0;36m_run\u001B[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001B[0m\n\u001B[1;32m   1179\u001B[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001B[0;32m-> 1180\u001B[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001B[0m\u001B[1;32m   1181\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001B[0m in \u001B[0;36m_do_run\u001B[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001B[0m\n\u001B[1;32m   1358\u001B[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001B[0;32m-> 1359\u001B[0;31m                            run_metadata)\n\u001B[0m\u001B[1;32m   1360\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001B[0m in \u001B[0;36m_do_call\u001B[0;34m(self, fn, *args)\u001B[0m\n\u001B[1;32m   1364\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1365\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1366\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0merrors\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mOpError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001B[0m in \u001B[0;36m_run_fn\u001B[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001B[0m\n\u001B[1;32m   1349\u001B[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001B[0;32m-> 1350\u001B[0;31m                                       target_list, run_metadata)\n\u001B[0m\u001B[1;32m   1351\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001B[0m in \u001B[0;36m_call_tf_sessionrun\u001B[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001B[0m\n\u001B[1;32m   1442\u001B[0m                                             \u001B[0mfetch_list\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtarget_list\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1443\u001B[0;31m                                             run_metadata)\n\u001B[0m\u001B[1;32m   1444\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-7-b1869f22d1f6>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      6\u001B[0m                              \u001B[0mfilter_triples\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfilter_triples\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m                              \u001B[0muse_default_protocol\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m                              verbose=True)\n\u001B[0m",
      "\u001B[0;32m~/anaconda3/lib/python3.6/site-packages/ampligraph/evaluation/protocol.py\u001B[0m in \u001B[0;36mevaluate_performance\u001B[0;34m(X, model, filter_triples, verbose, filter_unseen, entities_subset, corrupt_side, ranking_strategy, use_default_protocol)\u001B[0m\n\u001B[1;32m    917\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mdataset_handle\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    918\u001B[0m             \u001B[0mdataset_handle\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcleanup\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 919\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    920\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    921\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.6/site-packages/ampligraph/evaluation/protocol.py\u001B[0m in \u001B[0;36mevaluate_performance\u001B[0;34m(X, model, filter_triples, verbose, filter_unseen, entities_subset, corrupt_side, ranking_strategy, use_default_protocol)\u001B[0m\n\u001B[1;32m    905\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    906\u001B[0m         \u001B[0mlogger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdebug\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Making predictions.'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 907\u001B[0;31m         \u001B[0mranks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_ranks\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset_handle\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    908\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    909\u001B[0m         \u001B[0mlogger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdebug\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Ending Evaluation'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.6/site-packages/ampligraph/latent_features/models/EmbeddingModel.py\u001B[0m in \u001B[0;36mget_ranks\u001B[0;34m(self, dataset_handle)\u001B[0m\n\u001B[1;32m   1689\u001B[0m                     \u001B[0mranks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrank\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1690\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1691\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mranks\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1692\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1693\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfrom_idx\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001B[0m in \u001B[0;36m__exit__\u001B[0;34m(self, exec_type, exec_value, exec_tb)\u001B[0m\n\u001B[1;32m   1632\u001B[0m       \u001B[0mclose_thread\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdaemon\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1633\u001B[0m       \u001B[0mclose_thread\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstart\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1634\u001B[0;31m       \u001B[0mclose_thread\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m30.0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1635\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0mclose_thread\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_alive\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1636\u001B[0m         logging.error(\n",
      "\u001B[0;32m~/anaconda3/lib/python3.6/threading.py\u001B[0m in \u001B[0;36mjoin\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m   1058\u001B[0m             \u001B[0;31m# the behavior of a negative timeout isn't documented, but\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1059\u001B[0m             \u001B[0;31m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1060\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_wait_for_tstate_lock\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1061\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1062\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_wait_for_tstate_lock\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mblock\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.6/threading.py\u001B[0m in \u001B[0;36m_wait_for_tstate_lock\u001B[0;34m(self, block, timeout)\u001B[0m\n\u001B[1;32m   1070\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mlock\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# already determined that the C code is done\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1071\u001B[0m             \u001B[0;32massert\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_is_stopped\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1072\u001B[0;31m         \u001B[0;32melif\u001B[0m \u001B[0mlock\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0macquire\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mblock\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1073\u001B[0m             \u001B[0mlock\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrelease\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1074\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from ampligraph.evaluation import evaluate_performance\n",
    "\n",
    "filter_triples = np.concatenate((X_train, X_test))\n",
    "ranks = evaluate_performance(X_test,\n",
    "                             model=model,\n",
    "                             filter_triples=filter_triples,\n",
    "                             use_default_protocol=True,\n",
    "                             verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}